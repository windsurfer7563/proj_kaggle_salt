## Модели

  
  - Resnet34 c добавленными SE гейтами в декодере и hyupercolumn 
    на ЛБ скор с нее получился 0.845 
  (5 фолдов + флип тта ).
 - SE_Resnext50 - енкодер SE_ResNext50, декодер тотже 
        ЛБ 0.856 - по одной лучшией модели с 5 фолдов + флип тта)
        ЛБ 0.857 - 6 лучших снепшотов в каждом фолде (30 моделей)
 - SE_Resnext101 - ее еще не тестировал
 
 - IncV3 - показала худший скор 
    я ее сдесь оставил только для истории (даже незнаю рабочая ли она сейчас)
    
    
## пайплайн обучения:
    1) Претрейн - 30 эпох, BCE + dice лосс
    
    2) finetune - 80 эпох, lovasz лосс
    
    3) finetune2 - cycling lr (с восстановлением, тоесть начинаем с 0.01,
        по синусоиде спускаемся к 0.0005, дальше резко снова на 0.01 и т.д.)
        каждий цикл ~ 40 эпох (80000 степов(батчей)). LR апдейтится после каждого батча (а не после целой эпохи)
      
      Тренируем 6 циклов и сохраняем 6 лучших моделей. (сохранять нужно вручную с папки runs/debug)
    

